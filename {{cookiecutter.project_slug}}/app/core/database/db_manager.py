from fastapi import Depends
from sqlalchemy import AsyncAdaptedQueuePool, URL, Select, StaticPool, event
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from sqlalchemy.orm import sessionmaker
from sqlmodel import Session, SQLModel, create_engine
from typing import AsyncGenerator, Dict, Generator, Annotated, TypeVar, Type, Optional, Any, Callable, List, Union
from enum import Enum, auto
from app.core.logger import logger
from contextlib import asynccontextmanager, contextmanager
import os
import yaml
from pydantic import BaseModel, Field, model_validator, validator, root_validator
import asyncio
from functools import lru_cache
import time
from dataclasses import dataclass
from urllib.parse import quote_plus

from app.core.config import settings

# ç±»å‹å˜é‡ï¼Œç”¨äºæ³›å‹å‡½æ•°
T = TypeVar('T', bound=SQLModel)


class DatabaseType(str, Enum):
    """æ•°æ®åº“ç±»å‹æšä¸¾"""
    MYSQL = "mysql"
    POSTGRESQL = "postgresql"
    SQLITE = "sqlite"
    ORACLE = "oracle"
    MSSQL = "mssql"


@dataclass
class ConnectionInfo:
    """æ•°æ®åº“è¿æ¥ä¿¡æ¯"""
    host: str
    port: int
    database: str
    username: str = ""
    password: str = ""
    
    def __post_init__(self):
        """URLç¼–ç å¯†ç ä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        if self.password:
            self.password = quote_plus(self.password)


class DatabaseConfig(BaseModel):
    """æ•°æ®åº“é…ç½®æ¨¡å‹"""
    name: str
    db_type: DatabaseType
    sync_url: Optional[str] = None
    async_url: Optional[str] = None
    connection_info: Optional[ConnectionInfo] = None
    echo: bool = False
    pool_config: Dict[str, Any] = Field(default_factory=dict)
    connect_args: Dict[str, Any] = Field(default_factory=dict)
    is_default: bool = False
    health_check_interval: int = Field(default=30, ge=5, le=300)  # 5-300ç§’èŒƒå›´
    max_retries: int = Field(default=3, ge=1, le=10)  # 1-10æ¬¡é‡è¯•
    connection_timeout: int = Field(default=30, ge=5, le=120)  # è¿æ¥è¶…æ—¶

    @model_validator(mode="before")
    def validate_config(cls, values):
        """éªŒè¯é…ç½®çš„å®Œæ•´æ€§"""
        sync_url = values.get('sync_url')
        async_url = values.get('async_url')
        connection_info = values.get('connection_info')
        db_type = values.get('db_type')
        
        # å¿…é¡»æä¾›URLæˆ–è¿æ¥ä¿¡æ¯
        if not sync_url and not connection_info:
            raise ValueError("å¿…é¡»æä¾› sync_url æˆ– connection_info")
        
        # å¦‚æœæä¾›äº†è¿æ¥ä¿¡æ¯ä½†æ²¡æœ‰URLï¼Œè‡ªåŠ¨ç”ŸæˆURL
        if connection_info and not sync_url:
            values['sync_url'] = make_connection_url(
                db_type=db_type,
                username=connection_info.username,
                password=connection_info.password,
                host=connection_info.host,
                port=connection_info.port,
                database=connection_info.database
            )
        
        if connection_info and not async_url:
            values['async_url'] = make_async_connection_url(
                db_type=db_type,
                username=connection_info.username,
                password=connection_info.password,
                host=connection_info.host,
                port=connection_info.port,
                database=connection_info.database
            )
        
        return values
    
    def __init__(self, **data):
        super().__init__(**data)
        # SQLiteç‰¹æ®Šå¤„ç†
        if self.db_type == DatabaseType.SQLITE:
            if "check_same_thread" not in self.connect_args:
                self.connect_args["check_same_thread"] = False
            # SQLiteä¸éœ€è¦è¿æ¥æ± é…ç½®
            if not self.pool_config:
                self.pool_config = {"poolclass": StaticPool, "pool_pre_ping": True}

    @property
    def masked_sync_url(self) -> str:
        """è¿”å›æ©ç åçš„åŒæ­¥URLï¼ˆéšè—å¯†ç ï¼‰"""
        return self._mask_password_in_url(self.sync_url)
    
    @property
    def masked_async_url(self) -> str:
        """è¿”å›æ©ç åçš„å¼‚æ­¥URLï¼ˆéšè—å¯†ç ï¼‰"""
        return self._mask_password_in_url(self.async_url)
    
    def _mask_password_in_url(self, url: str) -> str:
        """åœ¨URLä¸­æ©ç å¯†ç """
        if not url or "://" not in url:
            return url
        
        try:
            parts = url.split("://")
            if len(parts) != 2:
                return url
            
            protocol, rest = parts
            if "@" in rest:
                auth, host_db = rest.split("@", 1)
                if ":" in auth:
                    username, _ = auth.split(":", 1)
                    return f"{protocol}://{username}:***@{host_db}"
            return url
        except Exception:
            return url


class DatabaseConfigManager:
    """æ•°æ®åº“é…ç½®ç®¡ç†å™¨"""
    def __init__(self):
        self.configs: Dict[str, DatabaseConfig] = {}
        self.default_source: str = "default"
        self._config_lock = asyncio.Lock() if hasattr(asyncio, 'current_task') else None
    
    def add_config(self, config: DatabaseConfig) -> None:
        """æ·»åŠ é…ç½®"""
        if config.name in self.configs:
            logger.warning(f"æ•°æ®æºé…ç½®å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–: {config.name}")
        
        self.configs[config.name] = config
        if config.is_default:
            self.default_source = config.name
            logger.info(f"ğŸŸ¢ åˆå§‹åŒ–æ•°æ®æºé»˜è®¤é…ç½®: {config.name} ({config.db_type}) è¿æ¥æ± é…ç½®{config.pool_config}")
    
    def get_config(self, name: Optional[str] = None) -> DatabaseConfig:
        """è·å–é…ç½®"""
        source_name = name or self.default_source
        if source_name not in self.configs:
            available = list(self.configs.keys())
            raise ValueError(f"æ•°æ®æºé…ç½®ä¸å­˜åœ¨: {source_name}, å¯ç”¨é…ç½®: {available}")
        return self.configs[source_name]
    
    def remove_config(self, name: str) -> None:
        """ç§»é™¤é…ç½®"""
        if name == self.default_source:
            raise ValueError(f"ä¸èƒ½ç§»é™¤é»˜è®¤æ•°æ®æºé…ç½®: {name}")
        if name in self.configs:
            del self.configs[name]
            logger.info(f"ç§»é™¤æ•°æ®æºé…ç½®: {name}")
    
    def load_from_yaml(self, config_path: str) -> None:
        """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®"""
        if not os.path.exists(config_path):
            logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config_data = yaml.safe_load(f)
            
            if not config_data or not isinstance(config_data, dict):
                logger.warning(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {config_path}")
                return
            
            # å¤„ç†æ•°æ®åº“é…ç½®
            db_configs = config_data.get('databases', [])
            for db_config in db_configs:
                try:
                    config = DatabaseConfig(**db_config)
                    self.add_config(config)
                except Exception as e:
                    logger.error(f"åŠ è½½æ•°æ®æºé…ç½®å¤±è´¥: {e}")
        
        except Exception as e:
            logger.error(f"åŠ è½½YAMLé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    def load_from_env(self) -> None:
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        try:
            db_count = 0
            while True:
                prefix = f"DB_{db_count}_"
                name_env = f"{prefix}NAME"
                
                if name_env not in os.environ:
                    break
                
                try:
                    config_data = self._parse_env_config(prefix)
                    config = DatabaseConfig(**config_data)
                    self.add_config(config)
                except Exception as e:
                    logger.error(f"åŠ è½½ç¯å¢ƒå˜é‡æ•°æ®æºé…ç½®å¤±è´¥: {e}")
                
                db_count += 1
        except Exception as e:
            logger.error(f"ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®å¤±è´¥: {e}")
    
    def _parse_env_config(self, prefix: str) -> Dict[str, Any]:
        """è§£æç¯å¢ƒå˜é‡é…ç½®"""
        name = os.environ[f"{prefix}NAME"]
        db_type_str = os.environ.get(f"{prefix}TYPE", "sqlite")
        
        try:
            db_type = DatabaseType(db_type_str.lower())
        except ValueError:
            logger.warning(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {db_type_str}ï¼Œä½¿ç”¨SQLite")
            db_type = DatabaseType.SQLITE
        
        config_data = {
            "name": name,
            "db_type": db_type,
            "is_default": os.environ.get(f"{prefix}DEFAULT", "false").lower() == "true",
        }
        
        # æ ¹æ®æ•°æ®åº“ç±»å‹æ„å»ºé…ç½®
        if db_type == DatabaseType.SQLITE:
            db_path = os.environ.get(f"{prefix}PATH", f"{name}.sqlite")
            config_data.update({
                "sync_url": f"sqlite:///{db_path}",
                "async_url": f"sqlite+aiosqlite:///{db_path}"
            })
        else:
            # é€šç”¨æ•°æ®åº“è¿æ¥å‚æ•°
            connection_info = ConnectionInfo(
                username=os.environ.get(f"{prefix}USERNAME", ""),
                password=os.environ.get(f"{prefix}PASSWORD", ""),
                host=os.environ.get(f"{prefix}HOST", "localhost"),
                port=int(os.environ.get(f"{prefix}PORT", self._get_default_port(db_type))),
                database=os.environ.get(f"{prefix}DATABASE", "")
            )
            config_data["connection_info"] = connection_info
        
        # è¿æ¥æ± é…ç½®
        pool_config = {}
        pool_mapping = {
            "POOL_SIZE": "pool_size",
            "MAX_OVERFLOW": "max_overflow", 
            "POOL_TIMEOUT": "pool_timeout",
            "POOL_RECYCLE": "pool_recycle"
        }
        
        for env_key, pool_key in pool_mapping.items():
            env_var = f"{prefix}{env_key}"
            if env_var in os.environ:
                pool_config[pool_key] = int(os.environ[env_var])
        
        if pool_config:
            config_data["pool_config"] = pool_config
        
        # å…¶ä»–é…ç½®
        optional_configs = {
            "HEALTH_CHECK_INTERVAL": "health_check_interval",
            "MAX_RETRIES": "max_retries",
            "CONNECTION_TIMEOUT": "connection_timeout"
        }
        
        for env_key, config_key in optional_configs.items():
            env_var = f"{prefix}{env_key}"
            if env_var in os.environ:
                config_data[config_key] = int(os.environ[env_var])
        
        return config_data
    
    def _get_default_port(self, db_type: DatabaseType) -> str:
        """è·å–æ•°æ®åº“é»˜è®¤ç«¯å£"""
        port_mapping = {
            DatabaseType.MYSQL: "3306",
            DatabaseType.POSTGRESQL: "5432",
            DatabaseType.ORACLE: "1521",
            DatabaseType.MSSQL: "1433"
        }
        return port_mapping.get(db_type, "5432")
    
    def load_default_config(self) -> None:
        """åŠ è½½é»˜è®¤é…ç½®"""
        try:
            if settings.USE_SQLITE:
                sync_url = settings.SQLITE_DATABASE_URI
                async_url = settings.SQLITE_DATABASE_URI.replace("sqlite:///", "sqlite+aiosqlite:///")
                db_type = DatabaseType.SQLITE
                connect_args = {"check_same_thread": False}
                pool_config = {"poolclass": StaticPool, "pool_pre_ping": True}
            else:
                sync_url = str(settings.SQLALCHEMY_DATABASE_URI)
                async_url = str(settings.SQLALCHEMY_DATABASE_URI).replace("postgresql://", "postgresql+asyncpg://")
                db_type = DatabaseType.POSTGRESQL
                connect_args = {}
                pool_config = {
                    'pool_size': settings.POOL_SIZE,
                    'max_overflow': settings.MAX_OVERFLOW,
                    'pool_timeout': settings.POOL_TIMEOUT,
                    'pool_recycle': settings.POOL_RECYCLE,
                    'pool_pre_ping': True,  # å¯ç”¨è¿æ¥é¢„æ£€
                }
            
            config = DatabaseConfig(
                name="default",
                db_type=db_type,
                sync_url=sync_url,
                async_url=async_url,
                echo=settings.ENVIRONMENT == "local",
                pool_config=pool_config,
                connect_args=connect_args,
                is_default=True
            )
            
            self.add_config(config)
        except Exception as e:
            logger.error(f"åŠ è½½é»˜è®¤é…ç½®å¤±è´¥: {e}")
            raise


class HealthChecker:
    """æ•°æ®åº“å¥åº·æ£€æŸ¥å™¨"""
    def __init__(self, db_manager: 'DatabaseManager'):
        self.db_manager = db_manager
        self._health_status: Dict[str, bool] = {}
        self._last_check: Dict[str, float] = {}
    
    async def check_source_health(self, source_name: str) -> bool:
        """æ£€æŸ¥å•ä¸ªæ•°æ®æºå¥åº·çŠ¶æ€"""
        try:
            config = self.db_manager.config_manager.get_config(source_name)
            current_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¥åº·æ£€æŸ¥
            last_check = self._last_check.get(source_name, 0)
            if current_time - last_check < config.health_check_interval:
                return self._health_status.get(source_name, True)
            
            # æ‰§è¡Œå¥åº·æ£€æŸ¥
            async with self.db_manager.get_async_session(source_name) as session:
                await session.execute("SELECT 1")
            
            self._health_status[source_name] = True
            self._last_check[source_name] = current_time
            return True
            
        except Exception as e:
            logger.warning(f"æ•°æ®æº {source_name} å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            self._health_status[source_name] = False
            self._last_check[source_name] = time.time()
            return False
    
    async def check_all_sources(self) -> Dict[str, bool]:
        """æ£€æŸ¥æ‰€æœ‰æ•°æ®æºå¥åº·çŠ¶æ€"""
        tasks = []
        for source_name in self.db_manager.get_all_source_names():
            tasks.append(self.check_source_health(source_name))
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        health_status = {}
        for i, source_name in enumerate(self.db_manager.get_all_source_names()):
            result = results[i]
            health_status[source_name] = result if isinstance(result, bool) else False
        
        return health_status


class DatabaseManager:
    """
    æ•°æ®åº“ç®¡ç†å™¨ï¼Œæ”¯æŒå¤šæ•°æ®æºç®¡ç†
    
    æä¾›åŒæ­¥å’Œå¼‚æ­¥æ•°æ®åº“è¿æ¥ä»¥åŠä¼šè¯ç®¡ç†ï¼Œå¯æ ¹æ®ä¸åŒä¸šåŠ¡éœ€æ±‚é€‰æ‹©ä¸åŒæ•°æ®æº
    """
    def __init__(self, config_manager: Optional[DatabaseConfigManager] = None):
        # å­˜å‚¨åŒæ­¥å¼•æ“å’Œä¼šè¯å·¥å‚
        self._sync_engines: Dict[str, Any] = {}
        self._sync_session_factories: Dict[str, Any] = {}

        # å­˜å‚¨å¼‚æ­¥å¼•æ“å’Œä¼šè¯å·¥å‚
        self._async_engines: Dict[str, Any] = {}
        self._async_session_factories: Dict[str, Any] = {}

        # é…ç½®ç®¡ç†å™¨
        self.config_manager = config_manager or DatabaseConfigManager()

        # å¥åº·æ£€æŸ¥å™¨
        self.health_checker = HealthChecker(self)

        # åˆå§‹åŒ–æ ‡å¿—
        self._initialized = False
        
        # ä¾èµ–ç¼“å­˜
        self._dependency_cache: Dict[str, Callable] = {}

        # åˆå§‹åŒ–é»˜è®¤æ•°æ®æº
        self._initialize_default_sources()
    
    def _initialize_default_sources(self):
        """åˆå§‹åŒ–é»˜è®¤æ•°æ®æº"""
        try:
            # åŠ è½½é»˜è®¤é…ç½®
            if not self.config_manager.configs:
                self.config_manager.load_default_config()
            
            # ä¸ºæ‰€æœ‰é…ç½®åˆ›å»ºå¼•æ“å’Œä¼šè¯
            for name, config in self.config_manager.configs.items():
                if name not in self._sync_engines:
                    self._create_engines_and_sessions(config)
            
            self._initialized = True            
            logger.info("ğŸŸ¢ æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    @property 
    def default_source(self) -> str:
        """è·å–é»˜è®¤æ•°æ®æºåç§°"""
        return self.config_manager.default_source
    
    def add_source(
        self,
        name: str,
        db_type: DatabaseType,
        sync_url: Optional[str] = None,
        async_url: Optional[str] = None,
        connection_info: Optional[ConnectionInfo] = None,
        echo: Optional[bool] = None,
        pool_config: Optional[Dict[str, Any]] = None,
        connect_args: Optional[Dict[str, Any]] = None,
        is_default: bool = False,
        **kwargs
    ):
        """æ·»åŠ æ•°æ®æº"""
        if echo is None:
            echo = settings.ENVIRONMENT == "local"
        
        config = DatabaseConfig(
            name=name,
            db_type=db_type,
            sync_url=sync_url,
            async_url=async_url,
            connection_info=connection_info,
            echo=echo,
            pool_config=pool_config or {},
            connect_args=connect_args or {},
            is_default=is_default,
            **kwargs
        )
        
        self.add_source_from_config(config)
    
    def add_source_from_config(self, config: DatabaseConfig):
        """ä»é…ç½®å¯¹è±¡æ·»åŠ æ•°æ®æº"""
        self.config_manager.add_config(config)
        self._create_engines_and_sessions(config) 
        
        # æ¸…é™¤ç›¸å…³çš„ä¾èµ–ç¼“å­˜
        self._clear_dependency_cache(config.name)

        logger.info(f"ğŸŸ¢ æˆåŠŸæ·»åŠ æ•°æ®æº: {config.name} ({config.db_type}), è¿æ¥æ± é…ç½®: {config.pool_config}")

    def _create_engines_and_sessions(self, config: DatabaseConfig):
        """åˆ›å»ºå¼•æ“å’Œä¼šè¯å·¥å‚"""
        try:
            # åˆ›å»ºåŒæ­¥å¼•æ“
            sync_engine = create_engine(
                config.sync_url,
                echo=config.echo,
                connect_args=config.connect_args,
                **config.pool_config
            )
            
            # æ·»åŠ è¿æ¥äº‹ä»¶ç›‘å¬å™¨
            self._setup_engine_events(sync_engine, config.name)
            
            # åˆ›å»ºåŒæ­¥ä¼šè¯å·¥å‚
            sync_session_factory = sessionmaker(
                autocommit=False,
                autoflush=False,
                bind=sync_engine,
                class_=Session
            )
            
            # åˆ›å»ºå¼‚æ­¥å¼•æ“
            async_pool_config = config.pool_config.copy()
            if 'poolclass' not in async_pool_config and config.db_type != DatabaseType.SQLITE:
                async_pool_config['poolclass'] = AsyncAdaptedQueuePool
            
            async_engine = create_async_engine(
                config.async_url,
                echo=config.echo,
                connect_args=config.connect_args,
                **async_pool_config
            )
            
            # åˆ›å»ºå¼‚æ­¥ä¼šè¯å·¥å‚
            async_session_factory = async_sessionmaker(
                autocommit=False,
                autoflush=False,
                bind=async_engine,
                expire_on_commit=False,
                class_=AsyncSession
            )
            
            # å­˜å‚¨å¼•æ“å’Œä¼šè¯å·¥å‚
            self._sync_engines[config.name] = sync_engine
            self._sync_session_factories[config.name] = sync_session_factory
            self._async_engines[config.name] = async_engine
            self._async_session_factories[config.name] = async_session_factory
            logger.info(f"ğŸŸ¢ æˆåŠŸåˆ›å»ºæ•°æ®æºå¼•æ“: {config.name}")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ•°æ®æºå¼•æ“å¤±è´¥: {config.name}, é”™è¯¯: {e}")
            raise
    
    def _setup_engine_events(self, engine, source_name: str):
        """è®¾ç½®å¼•æ“äº‹ä»¶ç›‘å¬å™¨"""
        @event.listens_for(engine, "connect")
        def set_sqlite_pragma(dbapi_connection, connection_record):
            """SQLiteç‰¹æ®Šé…ç½®"""
            if 'sqlite' in str(engine.url):
                cursor = dbapi_connection.cursor()
                cursor.execute("PRAGMA foreign_keys=ON")
                cursor.execute("PRAGMA journal_mode=WAL")
                cursor.close()
        
        @event.listens_for(engine, "checkout")
        def checkout_handler(dbapi_connection, connection_record, connection_proxy):
            """è¿æ¥æ£€å‡ºäº‹ä»¶"""
            logger.debug(f"æ•°æ®æº {source_name} è¿æ¥æ£€å‡º")
    
    async def remove_source(self, name: str):
        """ç§»é™¤æ•°æ®æº"""
        if name == self.default_source:
            logger.warning(f"ä¸èƒ½ç§»é™¤é»˜è®¤æ•°æ®æº: {name}")
            return
        
        # å…³é—­å¼•æ“
        if name in self._sync_engines:
            try:
                self._sync_engines[name].dispose()
                logger.info(f"å·²å…³é—­åŒæ­¥å¼•æ“: {name}")
            except Exception as e:
                logger.error(f"å…³é—­åŒæ­¥å¼•æ“å¤±è´¥: {name}, é”™è¯¯: {e}")
            finally:
                del self._sync_engines[name]
                del self._sync_session_factories[name]
        
        if name in self._async_engines:
            try:
                await self._async_engines[name].dispose()
                logger.info(f"å·²å…³é—­å¼‚æ­¥å¼•æ“: {name}")
            except Exception as e:
                logger.error(f"å…³é—­å¼‚æ­¥å¼•æ“å¤±è´¥: {name}, é”™è¯¯: {e}")
            finally:
                del self._async_engines[name]
                del self._async_session_factories[name]
        
        # ç§»é™¤é…ç½®å’Œæ¸…é™¤ç¼“å­˜
        try:
            self.config_manager.remove_config(name)
            self._clear_dependency_cache(name)
        except ValueError as e:
            logger.warning(str(e))
        
        logger.info(f"æˆåŠŸç§»é™¤æ•°æ®æº: {name}")
    
    def _clear_dependency_cache(self, source_name: str):
        """æ¸…é™¤ä¾èµ–ç¼“å­˜"""
        keys_to_remove = [key for key in self._dependency_cache.keys() if source_name in key]
        for key in keys_to_remove:
            del self._dependency_cache[key]
    
    def get_sync_engine(self, name: Optional[str] = None):
        """è·å–åŒæ­¥å¼•æ“"""
        source_name = name or self.default_source
        if source_name not in self._sync_engines:
            available = list(self._sync_engines.keys())
            raise ValueError(f"æ•°æ®æºä¸å­˜åœ¨: {source_name}, å¯ç”¨æ•°æ®æº: {available}")
        return self._sync_engines[source_name]
    
    def get_async_engine(self, name: Optional[str] = None):
        """è·å–å¼‚æ­¥å¼•æ“"""
        source_name = name or self.default_source
        if source_name not in self._async_engines:
            available = list(self._async_engines.keys())
            raise ValueError(f"æ•°æ®æºä¸å­˜åœ¨: {source_name}, å¯ç”¨æ•°æ®æº: {available}")
        return self._async_engines[source_name]
    
    @contextmanager
    def get_sync_session(self, name: Optional[str] = None) -> Generator[Session, None, None]:
        """è·å–åŒæ­¥ä¼šè¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        source_name = name or self.default_source
        if source_name not in self._sync_session_factories:
            available = list(self._sync_session_factories.keys())
            raise ValueError(f"æ•°æ®æºä¸å­˜åœ¨: {source_name}, å¯ç”¨æ•°æ®æº: {available}")
        
        sync_session = self._sync_session_factories[source_name]
        with sync_session() as session:
            try:
                yield session
            except Exception as e:
                session.rollback()
                logger.error(f"æ•°æ®æº {source_name} ä¼šè¯å¼‚å¸¸: {e}")
                raise
    
    @asynccontextmanager
    async def get_async_session(self, name: Optional[str] = None):
        """è·å–å¼‚æ­¥ä¼šè¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        source_name = name or self.default_source
        if source_name not in self._async_session_factories:
            available = list(self._async_session_factories.keys())
            raise ValueError(f"æ•°æ®æºä¸å­˜åœ¨: {source_name}, å¯ç”¨æ•°æ®æº: {available}")
        
        async_session = self._async_session_factories[source_name]
        async with async_session() as session:
            try:
                yield session
            except Exception as e:
                await session.rollback()
                logger.error(f"æ•°æ®æº {source_name} å¼‚æ­¥ä¼šè¯å¼‚å¸¸: {e}")
                raise


    # @lru_cache(maxsize=32)
    # def get_sync_session_dependency(self, name: Optional[str] = None) -> Callable:
    #     """è·å–åŒæ­¥ä¼šè¯çš„ä¾èµ–å‡½æ•°ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    #     source_name = name or self.default_source
    #     cache_key = f"sync_{source_name}"
        
    #     if cache_key not in self._dependency_cache:
    #         def _get_db():
    #             with self.get_sync_session(source_name) as session:
    #                 yield session

    #         # åŒ…è£…ä¸ºæ­£ç¡®çš„ä¾èµ–å‡½æ•°
    #         def _dependency():
    #             return _get_db()

    #         self._dependency_cache[cache_key] = _dependency

    #     return self._dependency_cache[cache_key]
    
    # @lru_cache(maxsize=32)
    # def get_async_session_dependency(self, name: Optional[str] = None) -> Callable:
    #     """è·å–å¼‚æ­¥ä¼šè¯çš„ä¾èµ–å‡½æ•°ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    #     source_name = name or self.default_source
    #     cache_key = f"async_{source_name}"
        
    #     if cache_key not in self._dependency_cache:
    #         async def _get_async_db():
    #             async with self.get_async_session(source_name) as session:
    #                 yield session

    #         # åŒ…è£…ä¸ºæ­£ç¡®çš„ä¾èµ–å‡½æ•°
    #         # def _dependency():
    #         #     return _get_async_db()

    #         self._dependency_cache[cache_key] = _get_async_db

    #     return self._dependency_cache[cache_key]
    
    def create_all(self, name: Optional[str] = None):
        """åˆ›å»ºæ‰€æœ‰è¡¨"""
        source_name = name or self.default_source
        engine = self.get_sync_engine(source_name)
        SQLModel.metadata.create_all(engine)  # ä»…åœ¨è¡¨ä¸å­˜åœ¨æ—¶åˆ›å»ºè¡¨ï¼Œä¸ä¿®æ”¹å·²æœ‰è¡¨
        logger.info(f"æˆåŠŸä¸ºæ•°æ®æº {source_name} åˆ›å»ºæ‰€æœ‰è¡¨")
    
    def drop_all(self, name: Optional[str] = None):
        """åˆ é™¤æ‰€æœ‰è¡¨ï¼ˆâš ï¸ è°¨æ…ä½¿ç”¨ï¼‰"""
        source_name = name or self.default_source
        engine = self.get_sync_engine(source_name)
        SQLModel.metadata.drop_all(engine)  # åˆ é™¤æ‰€æœ‰è¡¨ï¼ˆâš ï¸ ä¼šæ¸…ç©ºæ•°æ®ï¼ï¼‰
        logger.warning(f"å·²åˆ é™¤æ•°æ®æº {source_name} çš„æ‰€æœ‰è¡¨")

    async def dispose_all(self):
        """å…³é—­æ‰€æœ‰å¼•æ“ï¼Œé‡Šæ”¾èµ„æº"""
        # å…³é—­åŒæ­¥å¼•æ“
        for name, engine in list(self._sync_engines.items()):
            try:
                engine.dispose()
                logger.info(f"å·²å…³é—­åŒæ­¥å¼•æ“: {name}")
            except Exception as e:
                logger.error(f"å…³é—­åŒæ­¥å¼•æ“å¤±è´¥: {name}, é”™è¯¯: {e}")
        
        # å…³é—­å¼‚æ­¥å¼•æ“
        for name, engine in list(self._async_engines.items()):
            try:
                await engine.dispose()
                logger.info(f"å·²å…³é—­å¼‚æ­¥å¼•æ“: {name}")
            except Exception as e:
                logger.error(f"å…³é—­å¼‚æ­¥å¼•æ“å¤±è´¥: {name}, é”™è¯¯: {e}")
        
        # æ¸…ç©ºæ‰€æœ‰å­˜å‚¨
        self._sync_engines.clear()
        self._sync_session_factories.clear()
        self._async_engines.clear()
        self._async_session_factories.clear()
        self._dependency_cache.clear()
        
        logger.info("æ‰€æœ‰æ•°æ®åº“å¼•æ“å·²å…³é—­")
    
    def initialize_from_yaml(self, config_path: str):
        """ä»YAMLæ–‡ä»¶åˆå§‹åŒ–æ•°æ®æº"""
        self.config_manager.load_from_yaml(config_path)
        
        # ä¸ºæ–°é…ç½®åˆ›å»ºå¼•æ“å’Œä¼šè¯
        for name, config in self.config_manager.configs.items():
            if name not in self._sync_engines:
                self._create_engines_and_sessions(config)

    def initialize_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–æ•°æ®æº"""
        try:
            # é¦–å…ˆä»é…ç½®ç®¡ç†å™¨åŠ è½½ç¯å¢ƒå˜é‡é…ç½®
            self.config_manager.load_from_env()
            
            # ä¸ºæ–°é…ç½®åˆ›å»ºå¼•æ“å’Œä¼šè¯
            for name, config in self.config_manager.configs.items():
                if name not in self._sync_engines:
                    self._create_engines_and_sessions(config)
                    logger.info(f"ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–æ•°æ®æº: {name} ({config.db_type})")
            
            # éªŒè¯è‡³å°‘æœ‰ä¸€ä¸ªæ•°æ®æºè¢«åˆå§‹åŒ–
            if not self._sync_engines:
                logger.warning("æ²¡æœ‰ä»ç¯å¢ƒå˜é‡ä¸­åŠ è½½åˆ°ä»»ä½•æ•°æ®æºé…ç½®")
                # å¦‚æœæ²¡æœ‰ç¯å¢ƒå˜é‡é…ç½®ï¼Œç¡®ä¿æœ‰é»˜è®¤é…ç½®
                if not hasattr(self, '_initialized') or not self._initialized:
                    self._initialize_default_sources()
            else:
                self._initialized = True
                logger.info(f"æˆåŠŸä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–äº† {len(self._sync_engines)} ä¸ªæ•°æ®æº")
            
        except Exception as e:
            logger.error(f"ä»ç¯å¢ƒå˜é‡åˆå§‹åŒ–æ•°æ®æºå¤±è´¥: {e}")
            # å¦‚æœç¯å¢ƒå˜é‡åˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•åŠ è½½é»˜è®¤é…ç½®ä½œä¸ºå¤‡é€‰
            if not self._sync_engines:
                logger.info("å°è¯•åŠ è½½é»˜è®¤é…ç½®ä½œä¸ºå¤‡é€‰")
                try:
                    self._initialize_default_sources()
                except Exception as fallback_error:
                    logger.error(f"åŠ è½½é»˜è®¤é…ç½®ä¹Ÿå¤±è´¥: {fallback_error}")
                    raise RuntimeError(f"æ•°æ®æºåˆå§‹åŒ–å®Œå…¨å¤±è´¥: ç¯å¢ƒå˜é‡é”™è¯¯={e}, é»˜è®¤é…ç½®é”™è¯¯={fallback_error}")
            else:
                # å¦‚æœå·²æœ‰éƒ¨åˆ†æ•°æ®æºï¼Œåªè®°å½•è­¦å‘Š
                logger.warning(f"éƒ¨åˆ†ç¯å¢ƒå˜é‡é…ç½®åŠ è½½å¤±è´¥ï¼Œä½†å·²æœ‰ {len(self._sync_engines)} ä¸ªæ•°æ®æºå¯ç”¨")

    def get_all_source_names(self) -> List[str]:
        """è·å–æ‰€æœ‰æ•°æ®æºåç§°"""
        return list(self._sync_engines.keys())

    def get_source_info(self, name: Optional[str] = None) -> Dict[str, Any]:
        """è·å–æ•°æ®æºä¿¡æ¯"""
        source_name = name or self.default_source
        config = self.config_manager.get_config(source_name)
        
        sync_engine = self.get_sync_engine(source_name)
        async_engine = self.get_async_engine(source_name)
        
        return {
            "name": source_name,
            "type": config.db_type.value,
            "sync_url": config.masked_sync_url,
            "async_url": config.masked_async_url,
            "is_default": source_name == self.default_source,
            "echo": config.echo,
            "pool_config": config.pool_config,
            "connect_args": config.connect_args,
            "health_check_interval": config.health_check_interval,
            "max_retries": config.max_retries,
            "connection_timeout": config.connection_timeout,
            "sync_engine_pool_size": getattr(sync_engine.pool, 'size', None),
            "async_engine_pool_size": getattr(async_engine.pool, 'size', None),
        }

    def get_all_sources_info(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰æ•°æ®æºä¿¡æ¯"""
        return {
            name: self.get_source_info(name) 
            for name in self.get_all_source_names()
        }

    async def health_check(self, name: Optional[str] = None) -> Dict[str, Any]:
        """æ‰§è¡Œå¥åº·æ£€æŸ¥"""
        if name:
            # æ£€æŸ¥å•ä¸ªæ•°æ®æº
            is_healthy = await self.health_checker.check_source_health(name)
            config = self.config_manager.get_config(name)
            return {
                "source": name,
                "healthy": is_healthy,
                "type": config.db_type.value,
                "last_check": self.health_checker._last_check.get(name, 0)
            }
        else:
            # æ£€æŸ¥æ‰€æœ‰æ•°æ®æº
            health_status = await self.health_checker.check_all_sources()
            results = {}
            for source_name, is_healthy in health_status.items():
                config = self.config_manager.get_config(source_name)
                results[source_name] = {
                    "healthy": is_healthy,
                    "type": config.db_type.value,
                    "last_check": self.health_checker._last_check.get(source_name, 0)
                }
            return results

    async def reload_source_from_env(self, name: str):
        """ä»ç¯å¢ƒå˜é‡é‡æ–°åŠ è½½æŒ‡å®šæ•°æ®æº"""
        try:
            # æŸ¥æ‰¾ç¯å¢ƒå˜é‡é…ç½®
            db_count = 0
            target_config = None
            
            while True:
                prefix = f"DB_{db_count}_"
                name_env = f"{prefix}NAME"
                
                if name_env not in os.environ:
                    break
                
                env_name = os.environ[name_env]
                if env_name == name:
                    config_data = self.config_manager._parse_env_config(prefix)
                    target_config = DatabaseConfig(**config_data)
                    break
                
                db_count += 1
            
            if not target_config:
                raise ValueError(f"æœªæ‰¾åˆ°æ•°æ®æº {name} çš„ç¯å¢ƒå˜é‡é…ç½®")
            
            # ç§»é™¤æ—§çš„æ•°æ®æºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if name in self._sync_engines:
                await self.remove_source(name)
            
            # æ·»åŠ æ–°é…ç½®
            self.add_source_from_config(target_config)
            logger.info(f"æˆåŠŸä»ç¯å¢ƒå˜é‡é‡æ–°åŠ è½½æ•°æ®æº: {name}")
            
        except Exception as e:
            logger.error(f"ä»ç¯å¢ƒå˜é‡é‡æ–°åŠ è½½æ•°æ®æºå¤±è´¥: {name}, é”™è¯¯: {e}")
            raise

    async def test_connection(self, name: Optional[str] = None, max_retries: Optional[int] = None) -> Dict[str, Any]:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        source_name = name or self.default_source
        config = self.config_manager.get_config(source_name)
        retries = max_retries or config.max_retries
        
        result = {
            "source": source_name,
            "sync_connection": False,
            "async_connection": False,
            "errors": []
        }
        
        # æµ‹è¯•åŒæ­¥è¿æ¥
        for attempt in range(retries):
            try:
                with self.get_sync_session(source_name) as session:
                    session.execute("SELECT 1")
                result["sync_connection"] = True
                break
            except Exception as e:
                error_msg = f"åŒæ­¥è¿æ¥å°è¯• {attempt + 1}/{retries} å¤±è´¥: {e}"
                result["errors"].append(error_msg)
                if attempt < retries - 1:
                    await asyncio.sleep(1)  # é‡è¯•é—´éš”
        
        # æµ‹è¯•å¼‚æ­¥è¿æ¥
        for attempt in range(retries):
            try:
                async with self.get_async_session(source_name) as session:
                    await session.execute("SELECT 1")
                result["async_connection"] = True
                break
            except Exception as e:
                error_msg = f"å¼‚æ­¥è¿æ¥å°è¯• {attempt + 1}/{retries} å¤±è´¥: {e}"
                result["errors"].append(error_msg)
                if attempt < retries - 1:
                    await asyncio.sleep(1)  # é‡è¯•é—´éš”
        
        result["success"] = result["sync_connection"] and result["async_connection"]
        return result
    

# è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºæ•°æ®åº“è¿æ¥URL
def make_connection_url(
    db_type: DatabaseType,
    username: str,
    password: str,
    host: str,
    port: int,
    database: str,
    driver: str = None,
    **kwargs
) -> str:
    """
    åˆ›å»ºæ•°æ®åº“è¿æ¥URL
    
    Args:
        db_type: æ•°æ®åº“ç±»å‹
        username: ç”¨æˆ·å
        password: å¯†ç 
        host: ä¸»æœºåœ°å€
        port: ç«¯å£
        database: æ•°æ®åº“å
        driver: é©±åŠ¨ç¨‹åº
        **kwargs: é¢å¤–å‚æ•°
    
    Returns:
        str: æ•°æ®åº“è¿æ¥URL
    """
    # æ ¹æ®ä¸åŒæ•°æ®åº“ç±»å‹æ„å»ºURL
    if db_type == DatabaseType.MYSQL:
        driver = driver or "pymysql"
        return f"mysql+{driver}://{username}:{password}@{host}:{port}/{database}"
    
    elif db_type == DatabaseType.POSTGRESQL:
        driver = driver or "psycopg2"
        return f"postgresql+{driver}://{username}:{password}@{host}:{port}/{database}"
    
    elif db_type == DatabaseType.SQLITE:
        return f"sqlite:///{database}"
    
    elif db_type == DatabaseType.ORACLE:
        driver = driver or "cx_oracle"
        return f"oracle+{driver}://{username}:{password}@{host}:{port}/{database}"
    
    elif db_type == DatabaseType.MSSQL:
        driver = driver or "pyodbc"
        return f"mssql+{driver}://{username}:{password}@{host}:{port}/{database}"
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®åº“ç±»å‹: {db_type}")


# æ„å»ºå¼‚æ­¥æ•°æ®åº“è¿æ¥URL
def make_async_connection_url(
    db_type: DatabaseType,
    username: str,
    password: str,
    host: str,
    port: int,
    database: str,
    **kwargs
) -> str:
    """
    åˆ›å»ºå¼‚æ­¥æ•°æ®åº“è¿æ¥URL
    
    Args:
        db_type: æ•°æ®åº“ç±»å‹
        username: ç”¨æˆ·å
        password: å¯†ç 
        host: ä¸»æœºåœ°å€
        port: ç«¯å£
        database: æ•°æ®åº“å
        **kwargs: é¢å¤–å‚æ•°
    
    Returns:
        str: å¼‚æ­¥æ•°æ®åº“è¿æ¥URL
    """
    # æ ¹æ®ä¸åŒæ•°æ®åº“ç±»å‹æ„å»ºå¼‚æ­¥URL
    if db_type == DatabaseType.MYSQL:
        return f"mysql+aiomysql://{username}:{password}@{host}:{port}/{database}"
    
    elif db_type == DatabaseType.POSTGRESQL:
        return f"postgresql+asyncpg://{username}:{password}@{host}:{port}/{database}"
    
    elif db_type == DatabaseType.SQLITE:
        return f"sqlite+aiosqlite:///{database}"
    
    # å…¶ä»–æ•°æ®åº“ç±»å‹å¯èƒ½éœ€è¦ç‰¹å®šçš„å¼‚æ­¥é©±åŠ¨
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å¼‚æ­¥æ•°æ®åº“ç±»å‹: {db_type}")
    
    

# åˆ›å»ºå…¨å±€æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
config_manager = DatabaseConfigManager()
db_manager = DatabaseManager(config_manager)


# å¯¼å‡ºé»˜è®¤ä¾èµ–é¡¹ - ä½¿ç”¨å»¶è¿Ÿè·å–é¿å…åˆå§‹åŒ–é¡ºåºé—®é¢˜
def get_db_session():
    """è·å–é»˜è®¤æ•°æ®åº“ä¼šè¯ä¾èµ–"""
    with db_manager.get_sync_session() as session:
        yield session

async def get_async_db_session():
    """è·å–é»˜è®¤å¼‚æ­¥æ•°æ®åº“ä¼šè¯ä¾èµ–"""
    async with db_manager.get_async_session() as session:
        yield session

# å¯¼å‡ºAnnotatedä¾èµ–ç±»å‹
DbSessionDep = Annotated[Session, Depends(get_db_session)]
AsyncDbSessionDep = Annotated[AsyncSession, Depends(get_async_db_session)]

# å¯¼å‡ºå¸¸ç”¨çš„æ•°æ®åº“ç®¡ç†å™¨æ–¹æ³•ï¼Œæ–¹ä¾¿ä½¿ç”¨
def get_db_manager() -> DatabaseManager:
    """è·å–æ•°æ®åº“ç®¡ç†å™¨å®ä¾‹"""
    return db_manager

def get_session(source_name: Optional[str] = None):
    """è·å–æŒ‡å®šæ•°æ®æºçš„åŒæ­¥ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    return db_manager.get_sync_session(source_name)

async def get_async_session(source_name: Optional[str] = None):
    """è·å–æŒ‡å®šæ•°æ®æºçš„å¼‚æ­¥ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    return await db_manager.get_async_session(source_name)


# æ·»åŠ æ¸…ç†å‡½æ•°ï¼Œç”¨äºåº”ç”¨å…³é—­æ—¶è°ƒç”¨
async def cleanup_database_connections():
    """æ¸…ç†æ‰€æœ‰æ•°æ®åº“è¿æ¥"""
    try:
        await db_manager.dispose_all()
        logger.info("æ•°æ®åº“è¿æ¥æ¸…ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"æ•°æ®åº“è¿æ¥æ¸…ç†å¤±è´¥: {e}")




# ä½¿ç”¨ç¤ºä¾‹ å‚è€ƒ `tests/database-manager-example.py`

